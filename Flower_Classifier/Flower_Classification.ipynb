{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport cv2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6ea40fc68ead5bb1e30629c56e912f7d6798493"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/flowers/flowers\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adba247364f5c5ab88db5a0c8cda3bc7ffbee6d5"
      },
      "cell_type": "code",
      "source": "DAISY_DIR = '../input/flowers/flowers/daisy'\nDANDELION_DIR = \"../input/flowers/flowers/dandelion\"\nROSE_DIR = \"../input/flowers/flowers/rose\"\nSUNFLOWER_DIR = \"../input/flowers/flowers/sunflower\"\nTULIP_DIR = \"../input/flowers/flowers/tulip\"\nFLOWER_NAMES = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\nDIR = [DAISY_DIR, DANDELION_DIR, ROSE_DIR, SUNFLOWER_DIR, TULIP_DIR]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_training_data(flower_name, flower_dir,img_size):\n    \"\"\"\n        flower_name = string\n        flower_dir = input path\n        img_size = tuple (containing size of resized image)\n    \"\"\"\n    X = []\n    y = []\n    for num,i in enumerate(flower_dir):\n        for j in tqdm(os.listdir(i)):\n            path = os.path.join(i,j)\n            img = cv2.imread(path, cv2.IMREAD_COLOR)\n            try:\n                img = cv2.resize(img, img_size)\n            except:\n                continue\n                \n            X.append(np.array(img))\n            y.append(flower_name[num])\n    \n    return X,y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae816c7892785473afbdba91306faf13051b8750"
      },
      "cell_type": "code",
      "source": "X,y = create_training_data(FLOWER_NAMES, DIR, (200,200))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9195338264d31d0bfdbf08a18ddc8732ff841860"
      },
      "cell_type": "code",
      "source": "def view_random_images(X, y, random_state = 42):\n    np.random.seed(random_state)\n    plt.figure(figsize = (6,12))    \n    \n    for i in range(10):\n        plt.subplot(5,2,i+1)\n        num = np.random.randint(len(X))\n        plt.imshow(X[num])\n        plt.title(y[num])\n    \n    plt.tight_layout()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab59e7831c53ee1841e7dea748025d792a323f54"
      },
      "cell_type": "code",
      "source": "view_random_images(X,y, random_state = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21c67b9e74e3c9b3ea340e31a799b0284eccc72e"
      },
      "cell_type": "code",
      "source": "le = LabelEncoder()\ny = le.fit_transform(y)\ny = to_categorical(y,5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cbf1fb9849acf092ac28c345cc5f95073d13da3d"
      },
      "cell_type": "code",
      "source": "X = (np.array(X))/255\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\ndel X\ndel y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e507a60c93b2cdb42e8241c11a3b100c16503a3d"
      },
      "cell_type": "code",
      "source": "np.random.seed(42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03a93bafc04b2cf30c4c9da6e2734b297b3273c4"
      },
      "cell_type": "code",
      "source": "cnn = Sequential()\ncnn.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'same', activation = 'relu', input_shape = (200,200,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.2))\ncnn.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same', activation = 'relu', input_shape = (200,200,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.2))\ncnn.add(Conv2D(filters = 64, kernel_size = (4,4), padding = 'same', activation = 'relu', input_shape = (200,200,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.2))\ncnn.add(Conv2D(filters = 96, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (200,200,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Flatten())\ncnn.add(Dropout(0.15))\ncnn.add(Dense(512, activation = 'relu'))\ncnn.add(BatchNormalization())\ncnn.add(Dense(512, activation = 'relu'))\ncnn.add(BatchNormalization())\ncnn.add(Dense(5, activation = 'sigmoid'))\ncnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98f2ec43b8656a85351123879bb3359ee5f638da"
      },
      "cell_type": "code",
      "source": "cnn.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b61c2607111a988e95347543392c31c13450fde2"
      },
      "cell_type": "code",
      "source": "datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.16, # Randomly zoom image \n        width_shift_range=0.32,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.32,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\n\ndatagen.fit(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3cf0a0948fb3548e3cb40502d5c189781b344e0"
      },
      "cell_type": "code",
      "source": "#train = cnn.fit_generator(datagen.flow(X_train,y_train, batch_size=100),\n#                              epochs = 10, validation_data = (X_test,y_test),\n#                              verbose = 1, steps_per_epoch = X_train.shape[0])\n\nbatch_size = 100\nepochs = 24\n\ntrain = cnn.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 1, steps_per_epoch=X_train.shape[0]//16)\n\ncnn.save_weights('flower_classification_cnn_weights.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08e9e92e467f7d362079ce06a3caed7b42a5b0b8"
      },
      "cell_type": "code",
      "source": "plt.plot(train.history['loss'])\nplt.plot(train.history['val_loss'])\nplt.title('Loss Performance')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "066cbd21b0ad41560853a77dd2dc30cdda2a7dde"
      },
      "cell_type": "code",
      "source": "plt.plot(train.history['acc'])\nplt.plot(train.history['val_acc'])\nplt.title('Accuracy Performance')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}